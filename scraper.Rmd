---
title: "Web Scraper"
author: "Matt Peters"
output:
  cleanrmd::html_document_clean:
    theme: minicss
    df_print: paged
---
## Overview

This R script automates the process of downloading, extracting, cleaning, and merging multiple datasets from the Wisconsin DPI website. It compiles district-level data on average daily attendance, student homelessness, enrollment, high school graduation rates, ACT scores, free/reduced-price meal eligibility, and district costs. Each dataset is progressively merged into a single combined dataframe, which is used for the visualization and statistical analysis of educational trends across Wisconsin school districts on the following site:

[Read the full analysis here](index.html)

## Packages

```{r, message=FALSE, warning=FALSE, results='hide'}
library(tidyverse)
library(readxl)
library(rvest)
library(httr)
library(fs)
```

## Average Daily Attendance

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/wisedash/download-files/type?field_wisedash_upload_type_value=average_daily_attendance"
page <- read_html(base_url)
zip_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  str_subset("average_daily_attendance_\\d{4}-\\d{2}\\.zip") |> 
  unique()

temp_dir <- path_temp()
dir_create(temp_dir)
attendance_data <- list()

for (link in zip_links) {
  zip_path <- path(temp_dir, basename(link))
  GET(link, write_disk(zip_path, overwrite = TRUE))
  unzip(zip_path, exdir = temp_dir)
  excel_file <- dir_ls(temp_dir, regexp = "\\.xlsx?$")
  
  if (length(excel_file) == 1) {
    sheets <- excel_sheets(excel_file)
    
    if (length(sheets) == 1) {
      df <- read_excel(excel_file, sheet = 1)
    } else {
      df <- read_excel(excel_file, sheet = length(sheets), skip = 2)
    }

    df <- df |> 
      rename_with(~ str_replace_all(., "Attandance", "Attendance")) |> 
      mutate(`Dist Code` = str_pad(as.character(`Dist Code`), 
                                   width = 4, side = "left", pad = "0"),
             across(c(`Dist Code`, `District Name`), as.character),
             Year = str_extract(basename(excel_file), "\\d{4}"),
             across(c(`Days of Instruction`, `Actual Days of Attendance`,
                      `Possible Days of Attendance`, Year), as.numeric),
             `Attendance Rate` = `Actual Days of Attendance`/`Possible Days of Attendance`) |> 
      select(c(`Dist Code`, `District Name`, Year, `Attendance Rate`))

    attendance_data <- append(attendance_data, list(df))

  }
  
  file_delete(excel_file)
}

avg_attendance <- bind_rows(attendance_data)
```

## Homeless

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/wisedash/download-files/type?field_wisedash_upload_type_value=homeless"
page <- read_html(base_url)
zip_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  str_subset("homeless_certified_\\d{4}-\\d{2}\\.zip") |> 
  unique()

temp_dir <- path_temp()
dir_create(temp_dir)
homeless_data <- list()

for (link in zip_links) {
  zip_path <- path(temp_dir, basename(link))
  GET(link, write_disk(zip_path, overwrite = TRUE))
  unzip(zip_path, exdir = temp_dir)
  csv_file <- dir_ls(temp_dir, regexp = "\\.csv$") |> 
    str_subset("_layout", negate = TRUE)
  
  if (length(csv_file) == 1) {
    df <- read_csv(csv_file, show_col_types = FALSE)
    
    df <- df |> 
      mutate(Year = str_extract(basename(csv_file), "\\d{4}"),
             `DISTRICT_CODE` = str_pad(as.character(`DISTRICT_CODE`), 
                                       width = 4, side = "left", pad = "0"),
             across(c(Year, STUDENT_COUNT), as.numeric)) |> 
      filter(GROUP_BY_VALUE == "All Students",
         GRADE_GROUP == "[All]",
         UNACCOMPANIED_YOUTH_STATUS == "All Accompanied and Unaccompanied Youth",
         DISTRICT_CODE != "0000") |> 
      select(c(DISTRICT_CODE, Year, STUDENT_COUNT)) |> 
      rename("Homeless Count" = STUDENT_COUNT)
    
    homeless_data <- append(homeless_data, list(df))
  }

  file_delete(csv_file)
}

homeless <- bind_rows(homeless_data)

combined <- full_join(avg_attendance, homeless, 
                      by = c("Dist Code" = "DISTRICT_CODE", "Year" = "Year"))
```

## Enrollment

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/wisedash/download-files/type?field_wisedash_upload_type_value=Enrollment"
page <- read_html(base_url)
zip_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  str_subset("enrollment_certified_\\d{4}-\\d{2}\\.zip") |> 
  unique()

temp_dir <- path_temp()
dir_create(temp_dir)
enrollment_data <- list()

for (link in zip_links) {
  zip_path <- path(temp_dir, basename(link))
  GET(link, write_disk(zip_path, overwrite = TRUE))
  unzip(zip_path, exdir = temp_dir)
  csv_file <- dir_ls(temp_dir, regexp = "\\.csv$") |> 
    str_subset("_layout", negate = TRUE)
  
  if (length(csv_file) == 1) {
    df <- read_csv(csv_file, show_col_types = FALSE)
    
    df <- df |> 
      mutate(Year = str_extract(basename(csv_file), "\\d{4}"),
             `DISTRICT_CODE` = str_pad(as.character(`DISTRICT_CODE`), 
                                       width = 4, side = "left", pad = "0"),
             across(c(Year, STUDENT_COUNT), as.numeric)) |> 
      filter(GROUP_BY_VALUE == "All Students",
         GRADE_GROUP == "[All]",
         DISTRICT_CODE != "0000") |> 
      select(c(DISTRICT_CODE, Year, STUDENT_COUNT)) |>
      rename("Enrollment Count" = STUDENT_COUNT)
    
    enrollment_data <- append(enrollment_data, list(df))
  }

  file_delete(csv_file)
}

enrollment <- bind_rows(enrollment_data)

combined <- full_join(combined, enrollment, 
                      by = c("Dist Code" = "DISTRICT_CODE", "Year" = "Year"))
```

## Graduation Rates

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/wisedash/download-files/type?field_wisedash_upload_type_value=hs-completion"
page <- read_html(base_url)
zip_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  str_subset("hs_completion_certified_\\d{4}-\\d{2}\\.zip") |> 
  unique()

temp_dir <- path_temp()
dir_create(temp_dir)
hs_completion_data <- list()

for (link in zip_links) {
  zip_path <- path(temp_dir, basename(link))
  GET(link, write_disk(zip_path, overwrite = TRUE))
  unzip(zip_path, exdir = temp_dir)
  csv_file <- dir_ls(temp_dir, regexp = "\\.csv$") |> 
    str_subset("_layout", negate = TRUE)
  
  if (length(csv_file) == 1) {
    df <- read_csv(csv_file, show_col_types = FALSE)
    
    df <- df |> 
      mutate(Year = str_extract(basename(csv_file), "\\d{4}"),
             `DISTRICT_CODE` = str_pad(as.character(`DISTRICT_CODE`), 
                                       width = 4, side = "left", pad = "0"),
             across(c(Year, STUDENT_COUNT, COHORT_COUNT), as.numeric)) |> 
      filter(GROUP_BY_VALUE == "All Students",
         GRADE_GROUP == "[All]",
         DISTRICT_CODE != "0000",
         COMPLETION_STATUS %in% c("Completed - Regular High School Diploma", 
                                  "Completed - Other", 
                                  "Completed - Regular", 
                                  "Completed - HSED")) |> 
  group_by(DISTRICT_CODE, Year, COHORT) |>  
  summarize(Total_Completed = sum(STUDENT_COUNT, na.rm = TRUE), 
            Total_Cohort = first(COHORT_COUNT), 
            .groups = "drop") |> 
  group_by(DISTRICT_CODE, Year) |>
  summarize(`HS Completion Rate` = sum(Total_Completed) / sum(Total_Cohort), 
            .groups = "drop")
    
    hs_completion_data <- append(hs_completion_data, list(df))
  }

  file_delete(csv_file)
}

hs_completion <- bind_rows(hs_completion_data)

combined <- full_join(combined, hs_completion, 
                      by = c("Dist Code" = "DISTRICT_CODE", "Year" = "Year"))
```

## ACT Scores

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/wisedash/download-files/type?field_wisedash_upload_type_value=ACT11"
page <- read_html(base_url)
zip_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  str_subset("act_statewide_certified_\\d{4}-\\d{2}\\.zip") |> 
  unique()

temp_dir <- path_temp()
dir_create(temp_dir)
act_data <- list()

for (link in zip_links) {
  zip_path <- path(temp_dir, basename(link))
  GET(link, write_disk(zip_path, overwrite = TRUE))
  unzip(zip_path, exdir = temp_dir)
  csv_file <- dir_ls(temp_dir, regexp = "\\.csv$") |> 
    str_subset("_layout", negate = TRUE)
  
  if (length(csv_file) == 1) {
    df <- read_csv(csv_file, show_col_types = FALSE)
    
    df <- df |> 
      mutate(Year = str_extract(basename(csv_file), "\\d{4}"),
             `DISTRICT_CODE` = str_pad(as.character(`DISTRICT_CODE`), 
                                       width = 4, side = "left", pad = "0"),
             across(c(Year, STUDENT_COUNT, AVERAGE_SCORE), as.numeric)) |> 
      filter(GROUP_BY_VALUE == "All Students",
         GRADE_GROUP == "[All]",
         DISTRICT_CODE != "0000",
         TEST_SUBJECT == "Composite" | TEST_SUBJECT == "Writing",
         TEST_RESULT == "Not Benchmarked") |> 
      select(c(DISTRICT_CODE, Year, TEST_SUBJECT, AVERAGE_SCORE)) |> 
      mutate(AVERAGE_SCORE = if_else(Year == 2015 & TEST_SUBJECT == "Writing", 
                                     AVERAGE_SCORE / 3, AVERAGE_SCORE)) |> 
      pivot_wider(names_from = TEST_SUBJECT, 
                  values_from = AVERAGE_SCORE) |> 
      mutate(Writing = round(Writing, 2))
    
    act_data <- append(act_data, list(df))
  }

  file_delete(csv_file)
}

act <- bind_rows(act_data)

combined <- full_join(combined, act, 
                      by = c("Dist Code" = "DISTRICT_CODE", "Year" = "Year"))
```

## Free/Reduced-Price Eligibility (New)

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/school-nutrition/program-statistics"
page <- read_html(base_url)
excel_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  unique()

excel_links <- if_else(str_detect(excel_links, "^http"), 
                       excel_links, paste0("https://dpi.wi.gov", excel_links))

excel_links <- excel_links[str_detect(excel_links, regex("public", ignore_case = TRUE)) & 
                       str_detect(excel_links, regex("district", ignore_case = TRUE)) &
                       !str_detect(excel_links, regex("sbp", ignore_case = TRUE))]

temp_dir <- path_temp()
dir_create(temp_dir)
food_data <- list()

for (link in excel_links) {
  excel_path <- path(temp_dir, basename(link))
  GET(link, write_disk(excel_path, overwrite = TRUE))

  df <- read_excel(excel_path, sheet = 1)
  
  year <- str_extract(basename(link), "\\d{4}")

  df <- df |>
    filter(`Independent Charter` == "No") |> 
    mutate(DISTRICT_CODE = str_sub(`Agency Code`, -4),
           Year = year,
           across(c(Year, `% Free`, `% Reduced Price`, `% Free and Reduced`), as.numeric)) |> 
    select(c(DISTRICT_CODE, Year, `% Free`, `% Reduced Price`, `% Free and Reduced`)) 

  food_data[[basename(link)]] <- df

  file_delete(excel_path)
}

food <- bind_rows(food_data)
```

## Free/Reduced-Price Eligibility (Old)

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/school-nutrition/program-statistics/archive#epr"
page <- read_html(base_url)
excel_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  unique()

excel_links <- if_else(str_detect(excel_links, "^http"), 
                       excel_links, paste0("https://dpi.wi.gov", excel_links))

excel_links <- excel_links[str_detect(excel_links, regex("public-", ignore_case = TRUE)) & 
                       !str_detect(excel_links, regex("level", ignore_case = TRUE)) &
                       !str_detect(excel_links, regex("sb", ignore_case = TRUE))]

temp_dir <- path_temp()
dir_create(temp_dir)
food_data_2 <- list()

for (link in excel_links) {
  excel_path <- path(temp_dir, basename(link))
  GET(link, write_disk(excel_path, overwrite = TRUE))

  df <- read_excel(excel_path, sheet = 1)
  
  year <- str_extract(basename(link), "\\d{4}")

  df <- df |>
    rename_with(~ str_replace_all(., c("% Reduced" = "% Reduced Price",
                                       "%  Free" = "% Free",
                                       "%  Reduced" = "% Reduced Price"))) |> 
    mutate(DISTRICT_CODE = str_sub(`Agency Code`, -4),
           Year = year,
           across(c(Year, `% Free`, `% Reduced Price`, `% Free and Reduced`), as.numeric)) |> 
    select(c(DISTRICT_CODE, Year, `% Free`, `% Reduced Price`, `% Free and Reduced`)) 

  food_data_2[[basename(link)]] <- df

  file_delete(excel_path)
}

food2 <- bind_rows(food_data_2)

food <- bind_rows(food, food2)

combined <- full_join(combined, food, 
                      by = c("Dist Code" = "DISTRICT_CODE", "Year" = "Year"))
```

## Comparative Costs

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/sfs/statistical/cost-revenue/section-d#Item%202b"
page <- read_html(base_url)
excel_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  unique()

excel_links <- if_else(str_detect(excel_links, "^http"), 
                       excel_links, paste0("https://dpi.wi.gov", excel_links))
excel_links <- excel_links[str_detect(excel_links, 
                                      regex("cmpcst", ignore_case = TRUE))]
years <- str_extract(basename(excel_links), "\\d{2}") |> 
  as.numeric()
full_years <- if_else(years >= 30, 1900 + years, 2000 + years)
excel_links <- excel_links[full_years >= 2006]

temp_dir <- path_temp()
dir_create(temp_dir)
costs_data <- list()

for (link in excel_links) {
  excel_path <- path(temp_dir, basename(link))
  GET(link, write_disk(excel_path, overwrite = TRUE))
  
  year_short <- str_extract(basename(link), "\\d{2}") |>
    as.numeric()
  year <- if_else(year_short >= 30, 1899 + year_short, 1999 + year_short)

  raw_data <- read_excel(excel_path, sheet = "PER MEMBER", col_names = FALSE)
  header <- which(str_detect(raw_data[[1]], "CODE"))[1]
  df <- read_excel(excel_path, sheet = "PER MEMBER", skip = header - 1)

  df <- df |>
    mutate(DISTRICT_CODE = str_pad(as.character(CODE), 
                                   width = 4, side = "left", pad = "0"),
           Year = year,
           across(c(Year), as.numeric)) |> 
    filter(DISTRICT_CODE != "0000") |> 
    select(c(DISTRICT_CODE, Year, contains("TCEC"), contains("TEC"), contains("TDC"))) |> 
    drop_na()

  costs_data[[basename(link)]] <- df

  file_delete(excel_path)
}

costs <- bind_rows(costs_data)

combined <- full_join(combined, costs, 
                      by = c("Dist Code" = "DISTRICT_CODE", "Year" = "Year"))
```

## Comparative Revenue

```{r, message=FALSE, warning=FALSE, results='hide'}
base_url <- "https://dpi.wi.gov/sfs/statistical/cost-revenue/comparative-revenue-member"
page <- read_html(base_url)
excel_links <- page |> 
  html_nodes("a") |> 
  html_attr("href") |> 
  na.omit() |> 
  unique()

excel_links <- if_else(str_detect(excel_links, "^http"), 
                       excel_links, paste0("https://dpi.wi.gov", excel_links))
excel_links <- excel_links[str_detect(excel_links, 
                                      regex("cmprev", ignore_case = TRUE))]
years <- str_extract(basename(excel_links), "\\d{2}") |> 
  as.numeric()
full_years <- if_else(years >= 30, 1900 + years, 2000 + years)
excel_links <- excel_links[full_years >= 2011]

temp_dir <- path_temp()
dir_create(temp_dir)
revenue_data <- list()

for (link in excel_links) {
  excel_path <- path(temp_dir, basename(link))
  GET(link, write_disk(excel_path, overwrite = TRUE))
  
  year_short <- str_extract(basename(link), "\\d{2}") |>
    as.numeric()
  year <- if_else(year_short >= 30, 1899 + year_short, 1999 + year_short)

  raw_data <- read_excel(excel_path, sheet = "PER MEMBER", col_names = FALSE)
  header <- which(str_detect(raw_data[[1]], "CODE"))[1]
  df <- read_excel(excel_path, sheet = "PER MEMBER", skip = header - 1)

  df <- df |>
    mutate(DISTRICT_CODE = str_pad(as.character(CODE), 
                                   width = 4, side = "left", pad = "0"),
           Year = year,
           across(c(Year), as.numeric)) |> 
    filter(DISTRICT_CODE != "0000") |> 
    select(c(DISTRICT_CODE, Year, contains("TAX"), contains("REVENUE"), contains("REVENUES"))) |> 
    drop_na()

  revenue_data[[basename(link)]] <- df

  file_delete(excel_path)
}
 
revenue <- bind_rows(revenue_data)

combined <- full_join(combined, revenue,
                      by = c("Dist Code" = "DISTRICT_CODE", "Year" = "Year"))
```

## Completed Dataframe

```{r, message=FALSE, warning=FALSE, results='hide'}
school_data <- combined |> 
  group_by(`Dist Code`) |>  
  fill(`District Name`, .direction = "downup") |> 
  ungroup() |> 
  mutate(`Homeless Share` = `Homeless Count` / `Enrollment Count`,
         local_revenue = `PROPERTY TAX` + `REVENUE`,
         rev_cost_ratio = `REVENUES` / `PER MEMBER (TDC)`,
         size = case_when(
           `Enrollment Count` < 1000 ~ "Small",
           `Enrollment Count` >= 1000 & `Enrollment Count` < 6000 ~ "Medium",
           `Enrollment Count` >= 6000 ~ "Large"
         )) |> 
  rename(dist_code = `Dist Code`,
         dist_name = `District Name`,
         year = Year,
         attendance_rate = `Attendance Rate`,
         enrollment = `Enrollment Count`,
         graduation_rate = `HS Completion Rate`,
         act_composite = Composite,
         act_writing = Writing,
         reduced_share = `% Reduced Price`,
         free_share = `% Free`,
         lunch_share = `% Free and Reduced`,
         homeless_share = `Homeless Share`,
         tcec = `PER MEMBER (TCEC)`,
         tec = `PER MEMBER (TEC)`,
         tdc = `PER MEMBER (TDC)`,
         all_revenue = `REVENUES`) |> 
  select(c(year, dist_name, dist_code, enrollment, size, attendance_rate, 
           reduced_share, free_share, lunch_share, homeless_share, graduation_rate, 
           act_composite, act_writing, local_revenue, all_revenue, tcec, tec, tdc, rev_cost_ratio)) |> 
  mutate(attendance_rate = round(attendance_rate, 5),
         reduced_share = round(reduced_share, 5),          
         free_share = round(free_share, 5),          
         lunch_share = round(lunch_share, 5),          
         homeless_share = round(homeless_share, 5),    
         graduation_rate = round(graduation_rate, 5),
         all_revenue = round(all_revenue, 0),
         local_revenue = round(local_revenue, 0),
         tcec = round(tcec, 0),
         tec = round(tec, 0),
         tdc = round(tdc, 0), 
         rev_cost_ratio = round(rev_cost_ratio, 5))

write_csv(school_data, "data/school_data.csv")
```
